{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Snorkel Session and Load Data\n",
    "Creates a snorkel session on SQLite database and loads tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Exercise = candidate_subclass('Exercise', ['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "tweets_file_path = 'data/unlabeled_tweets.txt'\n",
    "\n",
    "with open(tweets_file_path, 'r') as f:\n",
    "    tweets = f.readlines()\n",
    "    for t in tweets:\n",
    "        docs.append(t.strip())\n",
    "\n",
    "train_set = set()\n",
    "dev_set = set()\n",
    "test_set = set()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    if i % 10 == 8:\n",
    "        dev_set.add(doc)\n",
    "    elif i % 10 == 9:\n",
    "        test_set.add(doc)\n",
    "    else:\n",
    "        train_set.add(doc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "cand_extractor = CandidateExtractor(Exercise, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 12031)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 1515)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 1514)\n",
      "CPU times: user 3.88 s, sys: 296 ms, total: 4.18 s\n",
      "Wall time: 4.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, docs in enumerate([train_set, dev_set, test_set]):    \n",
    "    cand_extractor.apply(docs, split=i)\n",
    "    print(\"Number of candidates:\", session.query(Exercise).filter(Exercise.split == i).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 215\n",
      "AnnotatorLabels created: 215\n",
      "CPU times: user 5.89 s, sys: 28 ms, total: 5.92 s\n",
      "Wall time: 6.4 s\n"
     ]
    }
   ],
   "source": [
    "# Load Gold Labels\n",
    "from util import load_external_labels\n",
    "%time missed = load_external_labels(session, Exercise, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1515, 1), (1514, 1))\n"
     ]
    }
   ],
   "source": [
    "# Load existing dev and test sets\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "print(L_gold_dev.shape, L_gold_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Functions (LFs)\n",
    "LF is a python function that accepts a tweet and returns 1 if it marks it as true, -1 if false, or 0 to abstain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks for a kb phrase in the tweet\n",
    "kb = 'data/kb.txt'            \n",
    "def LF_distant_supervision(c):   \n",
    "    with open(kb) as f:\n",
    "        label = -1\n",
    "        for phrase in f:\n",
    "            if c.content.find(phrase.strip()) >= 0:\n",
    "                label = 1         \n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use weak classifier\n",
    "from snorkel.weak_classifier import *\n",
    "\n",
    "# First train the classifier\n",
    "vec, clf = train_classifier()\n",
    "\n",
    "def LF_weak_classifier(c):\n",
    "    label = classify(vec, clf, [c.content])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some random LF\n",
    "import random\n",
    "\n",
    "def LF_random_lf(c):\n",
    "    return random.choice([-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another random LF\n",
    "def LF_another_random_lf(c):\n",
    "    return random.choice([-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group LFs in a list for later use\n",
    "#LFs = [LF_distant_supervision, LF_weak_classifier, LF_random_lf, LF_another_random_lf]\n",
    "LFs = [LF_distant_supervision, LF_weak_classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number labeled:', 119)\n"
     ]
    }
   ],
   "source": [
    "# Check size of dev set labeled as exercise tweets using LF_distant_supervision\n",
    "labeled = []\n",
    "for c in session.query(Exercise).filter(Exercise.split == 1):\n",
    "    if LF_distant_supervision(c) == 1:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.784\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            1.0\n",
      "Recall               0.784\n",
      "F1                   0.879\n",
      "----------------------------------------\n",
      "TP: 76 | FP: 0 | TN: 0 | FN: 21\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of LF_distant_supervision on dev set\n",
    "from snorkel.lf_helpers import test_LF\n",
    "tp, fp, tn, fn = test_LF(session, LF_distant_supervision, split=1, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 95 | FP: 0 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of LF_weak_classifier on dev set\n",
    "from snorkel.lf_helpers import test_LF\n",
    "tp, fp, tn, fn = test_LF(session, LF_weak_classifier, split=1, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LFs\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 25.2 s, sys: 184 ms, total: 25.4 s\n",
      "Wall time: 25.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<12031x2 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 13804 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run labeler\n",
    "import numpy as np\n",
    "np.random.seed(1701)\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 0 ns, total: 152 ms\n",
      "Wall time: 150 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<12031x2 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 13804 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the labels as a sparse matrix\n",
    "%time L_train = labeler.load_matrix(session, split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147369</td>\n",
       "      <td>0.090433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_weak_classifier</th>\n",
       "      <td>1</td>\n",
       "      <td>0.147369</td>\n",
       "      <td>0.147369</td>\n",
       "      <td>0.090433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        j  Coverage  Overlaps  Conflicts\n",
       "LF_distant_supervision  0  1.000000  0.147369   0.090433\n",
       "LF_weak_classifier      1  0.147369  0.147369   0.090433"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View statistics about the resulting label matrix\n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generative Model\n",
    "\n",
    "Train a model of the LFs to estimate their accuracies and then combine the outputs of the LFs into a noise-aware training labels set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.62641656,  0.04909397])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply gen model to the training candidates to get the noise-aware training label set (training marginals)\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the training marginals\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.961620</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.963480</td>\n",
       "      <td>0.813912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.527202</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>0.533883</td>\n",
       "      <td>0.343682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Coverage  Precision    Recall\n",
       "0  0.961620    0.8442   0.963480  0.813912\n",
       "1  0.527202    0.6654   0.533883  0.343682"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learned accuracy parameters, and other statistics about the LFs learned by the generative model\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate on Labeling Functions\n",
    "Improve the LF set.  First, apply the LFs to the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.784\n",
      "Neg. class accuracy: 0.97\n",
      "Precision            0.639\n",
      "Recall               0.784\n",
      "F1                   0.704\n",
      "----------------------------------------\n",
      "TP: 76 | FP: 43 | TN: 1375 | FN: 21\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the score of the generative model\n",
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141254</td>\n",
       "      <td>0.080528</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.965525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_weak_classifier</th>\n",
       "      <td>1</td>\n",
       "      <td>0.141254</td>\n",
       "      <td>0.141254</td>\n",
       "      <td>0.080528</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
       "LF_distant_supervision  0  1.000000  0.141254   0.080528  76   0  21   0   \n",
       "LF_weak_classifier      1  0.141254  0.141254   0.080528  95   0   0   0   \n",
       "\n",
       "                        Empirical Acc.  Learned Acc.  \n",
       "LF_distant_supervision        0.783505      0.965525  \n",
       "LF_weak_classifier            1.000000      0.519736  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore some of the additional functionalities of the lf_stats method for the dev set\n",
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the training labels\n",
    "\n",
    "Save the `training_marginals` (**probabilistic training labels**) for later use to train an end extraction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 12031 marginals\n",
      "CPU times: user 6.65 s, sys: 52 ms, total: 6.7 s\n",
      "Wall time: 6.8 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an End Extraction Model\n",
    "Use the noisy training labels to train the end extraction model (Bi-LSTM, a state-of-the-art deep neural network). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the probabilistic training labels\n",
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the candidates\n",
    "train_cands = session.query(Exercise).filter(Exercise.split == 0).order_by(Exercise.id).all()\n",
    "dev_cands   = session.query(Exercise).filter(Exercise.split == 1).order_by(Exercise.id).all()\n",
    "test_cands  = session.query(Exercise).filter(Exercise.split == 2).order_by(Exercise.id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gold labels for evaluation\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom snorkel.learning.disc_models.rnn import reRNN\\n\\ntrain_kwargs = {\\n    'lr':         0.01,\\n    'dim':        50,\\n    'n_epochs':   10,\\n    'dropout':    0.25,\\n    'print_freq': 1,\\n    'max_sentence_length': 100\\n}\\n\\nlstm = reRNN(seed=1701, n_threads=None)\\nlstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the discriminative model\n",
    "'''\n",
    "from snorkel.learning.disc_models.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        50,\n",
    "    'n_epochs':   10,\n",
    "    'dropout':    0.25,\n",
    "    'print_freq': 1,\n",
    "    'max_sentence_length': 100\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats from the discriminative model\n",
    "#p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "#print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions of the model to database\n",
    "#lstm.save_marginals(session, test_cands)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
