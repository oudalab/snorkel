{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Snorkel Session and Load Data\n",
    "Creates a snorkel session on SQLite database and loads tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Exercise = candidate_subclass('Exercise', ['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "docs = []\n",
    "tweets_file_path = 'data/unlabeled_tweets.tsv'\n",
    "\n",
    "tweets = pd.read_csv(tweets_file_path, sep = '\\t')\n",
    "for idx, row in tweets.iterrows():\n",
    "    docs.append(row['content'])\n",
    "    \n",
    "train_set = set()\n",
    "dev_set = set()\n",
    "test_set = set()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    if i % 10 == 8:\n",
    "        dev_set.add(doc)\n",
    "    elif i % 10 == 9:\n",
    "        test_set.add(doc)\n",
    "    else:\n",
    "        train_set.add(doc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "cand_extractor = CandidateExtractor(Exercise, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 1307)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 163)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 163)\n",
      "CPU times: user 964 ms, sys: 168 ms, total: 1.13 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, docs in enumerate([train_set, dev_set, test_set]):    \n",
    "    cand_extractor.apply(docs, split=i)\n",
    "    print(\"Number of candidates:\", session.query(Exercise).filter(Exercise.split == i).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 18\n",
      "AnnotatorLabels created: 24\n",
      "CPU times: user 920 ms, sys: 0 ns, total: 920 ms\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "# Load Gold Labels\n",
    "from util import load_external_labels\n",
    "%time missed = load_external_labels(session, Exercise, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((163, 1), (163, 1))\n"
     ]
    }
   ],
   "source": [
    "# Load existing dev and test sets\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "print(L_gold_dev.shape, L_gold_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Functions (LFs)\n",
    "LF is a python function that accepts a tweet and returns 1 if it marks it relevant, 2 if irrelevant, 3 if junk, or 0 to abstain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks for a kb phrase in the tweet\n",
    "kb = 'data/kb.txt'\n",
    "def is_exercise(c):\n",
    "    with open(kb) as f:\n",
    "        for phrase in f:\n",
    "            if c.content.find(phrase.strip()) >= 0:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Look for person names\n",
    "def has_person(c):\n",
    "    ents = [e.label_ for e in nlp(c.content).ents]\n",
    "    for l in ents:\n",
    "        if l == 'PERSON':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ME = [\"I\", \"me\", \"Me\", \"I'm\", \"I am\", \"i am\", \"im\", \"we\", \"WE\", \"We\"]\n",
    "NOTME = [\"He\", \"She\", \"he\", \"she\", \"His\", \"his\", \"her\", \"our\", \"your\", \"my\", \"My\", \"Your\", \"Our\", \"they\", \"They\", \"Their\", \"their\"]\n",
    "\n",
    "def LF_1(c):\n",
    "    if is_exercise(c):\n",
    "        for me in ME:\n",
    "            if me in c.content.split():\n",
    "                #print('me = {0} => {1}'.format(me, c.content))\n",
    "                return 1\n",
    "        return 0\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_2(c):\n",
    "    if is_exercise(c):\n",
    "        if has_person(c):\n",
    "            return 2\n",
    "        else:\n",
    "            for o in NOTME:\n",
    "                if o in c.content.split():   \n",
    "                    #print('other = {0} => {1}'.format(o, c.content))\n",
    "                    return 2\n",
    "            return 0\n",
    "    return 3               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_3(c):    \n",
    "    for idx, tweet in tweets.iterrows():\n",
    "        if c.content == tweet['content']:\n",
    "            #print('content = {0}, label = {1}'.format(c.content, tweet['label']))\n",
    "            return tweet['label']\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use weak classifier\n",
    "from snorkel.weak_classifier import train_classifier, classify\n",
    "\n",
    "# First train the classifier\n",
    "vec, clf = train_classifier()\n",
    "\n",
    "def LF_weak_classifier(c):\n",
    "    label = classify(vec, clf, [c.content])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group LFs in a list for later use\n",
    "LFs = [LF_1, LF_2, LF_3, LF_weak_classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number labeled:', 34)\n"
     ]
    }
   ],
   "source": [
    "# Check size of dev set labeled as exercise tweets using LF_distant_supervision\n",
    "labeled = []\n",
    "for c in session.query(Exercise).filter(Exercise.split == 1):\n",
    "    if LF_weak_classifier(c) == 1:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LFs\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 1min 14s, sys: 1.28 s, total: 1min 15s\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1307x4 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 4010 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run labeler\n",
    "import numpy as np\n",
    "np.random.seed(1701)\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2, 1, 1],\n",
       "        [1, 2, 3, 1],\n",
       "        [1, 2, 1, 1],\n",
       "        ..., \n",
       "        [3, 3, 3, 3],\n",
       "        [0, 2, 1, 1],\n",
       "        [0, 0, 1, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 ms, sys: 0 ns, total: 56 ms\n",
      "Wall time: 54.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1307x4 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 4010 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the labels as a sparse matrix\n",
    "%time L_train = labeler.load_matrix(session, split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.504208</td>\n",
       "      <td>0.504208</td>\n",
       "      <td>0.329763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.563887</td>\n",
       "      <td>0.563887</td>\n",
       "      <td>0.403213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_weak_classifier</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    j  Coverage  Overlaps  Conflicts\n",
       "LF_1                0  0.504208  0.504208   0.329763\n",
       "LF_2                1  0.563887  0.563887   0.403213\n",
       "LF_3                2  1.000000  1.000000   0.623565\n",
       "LF_weak_classifier  3  1.000000  1.000000   0.623565"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View statistics about the resulting label matrix\n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generative Model\n",
    "\n",
    "Train a model of the LFs to estimate their accuracies and then combine the outputs of the LFs into a noise-aware training labels set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 3\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.57933113,  0.38535937,  1.18776478,  1.2978771 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply gen model to the training candidates to get the noise-aware training label set (training marginals)\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAD/BJREFUeJzt3X+MZWV9x/H3R1ak/gKEKaG7q0sj2hJII50IxsRa11pcDUtSJDRVVrLtJlatFdO6/ZFgtH9gf0gxMdqt2C6NtVBqyqbSGgIY0qYQB7GsQK1bRNgtyCiw/UGsUr/94z7o7LK7Mztn5t6dfd6vZDLnPOe593yf+XE/c55z7plUFZKk/jxr0gVIkibDAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1atV8HZJ8Cngz8GhVndnaXgRcC6wDHgAuqqrHkwS4CtgAPAm8vaq+1B6zCfjd9rS/V1Xb59v3ySefXOvWrTvMIUlS3+68885vVdXUfP0y360gkrwG+G/gmjkB8PvAY1V1RZKtwIlV9f4kG4B3MwqAc4CrquqcFhgzwDRQwJ3AT1fV44fa9/T0dM3MzMw3BknSHEnurKrp+frNOwVUVbcBj+3XvBF4+i/47cAFc9qvqZHbgROSnAr8PHBTVT3WXvRvAs5b2FAkScthsecATqmqh9vyI8ApbXk18NCcfrtb28HaJUkTMvgkcI3mkJbslqJJtiSZSTIzOzu7VE8rSdrPYgPgm21qh/b50da+B1g7p9+a1naw9meoqm1VNV1V01NT857DkCQt0mIDYAewqS1vAm6Y035JRs4F9rapos8Db0hyYpITgTe0NknShCzkMtDPAK8FTk6yG7gcuAK4Lslm4BvARa37jYyuANrF6DLQSwGq6rEkHwK+2Pp9sKr2P7EsSRqjeS8DnSQvA5Wkw7dkl4FKko5OBoAkdWrecwBHlQ8cv9/63snUIUlHAI8AJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdWrVpAtYTuu2fm6f9QeOm1AhknQE8ghAkjplAEhSpwwASeqUASBJnRoUAEnem+SeJF9J8pkkxyU5LckdSXYluTbJsa3vc9r6rrZ93VIMQJK0OIsOgCSrgV8DpqvqTOAY4GLgw8CVVfVS4HFgc3vIZuDx1n5l6ydJmpChU0CrgB9Jsgp4LvAw8Drg+rZ9O3BBW97Y1mnb1yfJwP1LkhZp0QFQVXuAPwQeZPTCvxe4E3iiqp5q3XYDq9vyauCh9tinWv+TFrt/SdIwQ6aATmT0V/1pwI8BzwPOG1pQki1JZpLMzM7ODn06SdJBDJkCej3w9aqararvAZ8FXg2c0KaEANYAe9ryHmAtQNt+PPDt/Z+0qrZV1XRVTU9NTQ0oT5J0KEMC4EHg3CTPbXP564F7gVuBC1ufTcANbXlHW6dtv6WqasD+JUkDDDkHcAejk7lfAna259oGvB+4LMkuRnP8V7eHXA2c1NovA7YOqFuSNNCgm8FV1eXA5fs13w+88gB9vwO8Zcj+JElLx3cCS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp1ZNugBJEpy1/ax91ndu2rns+xx0BJDkhCTXJ/nXJPcleVWSFyW5KcnX2ucTW98k+WiSXUnuTnL20gxBkrQYQ6eArgL+oap+Avgp4D5gK3BzVZ0O3NzWAd4InN4+tgAfH7hvSdIAiw6AJMcDrwGuBqiq71bVE8BGYHvrth24oC1vBK6pkduBE5KcuujKJUmDDDkCOA2YBf4syV1JPpnkecApVfVw6/MIcEpbXg08NOfxu1vbPpJsSTKTZGZ2dnZAeZKkQxkSAKuAs4GPV9UrgP/hh9M9AFRVAXU4T1pV26pquqqmp6amBpQnSTqUIQGwG9hdVXe09esZBcI3n57aaZ8fbdv3AGvnPH5Na5MkTcCiA6CqHgEeSvLy1rQeuBfYAWxqbZuAG9ryDuCSdjXQucDeOVNFkqQxG/o+gHcDn05yLHA/cCmjULkuyWbgG8BFre+NwAZgF/Bk6ytJmpBBAVBVXwamD7Bp/QH6FvDOIfuTJC0dbwUhSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVODAyDJMUnuSvJ3bf20JHck2ZXk2iTHtvbntPVdbfu6ofuWJC3eUhwBvAe4b876h4Erq+qlwOPA5ta+GXi8tV/Z+kmSJmRQACRZA7wJ+GRbD/A64PrWZTtwQVve2NZp29e3/pKkCRh6BPDHwG8C32/rJwFPVNVTbX03sLotrwYeAmjb97b++0iyJclMkpnZ2dmB5UmSDmbRAZDkzcCjVXXnEtZDVW2rqumqmp6amlrKp5YkzbFqwGNfDZyfZANwHPBC4CrghCSr2l/5a4A9rf8eYC2wO8kq4Hjg2wP2L0kaYNFHAFX1W1W1pqrWARcDt1TVLwG3Ahe2bpuAG9ryjrZO235LVdVi9y9JGmY53gfwfuCyJLsYzfFf3dqvBk5q7ZcBW5dh35KkBRoyBfQDVfUF4Att+X7glQfo8x3gLUuxP0nScL4TWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqdWTbqASTpr+1n7rO/ctHNClUjS+HkEIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjq16ABIsjbJrUnuTXJPkve09hcluSnJ19rnE1t7knw0ya4kdyc5e6kGIUk6fEOOAJ4C3ldVZwDnAu9McgawFbi5qk4Hbm7rAG8ETm8fW4CPD9i3JGmgRQdAVT1cVV9qy/8F3AesBjYC21u37cAFbXkjcE2N3A6ckOTURVcuSRpkSc4BJFkHvAK4Azilqh5umx4BTmnLq4GH5jxsd2uTJE3A4ABI8nzgb4Bfr6r/nLutqgqow3y+LUlmkszMzs4OLU+SdBCDAiDJsxm9+H+6qj7bmr/59NRO+/xoa98DrJ3z8DWtbR9Vta2qpqtqempqakh5kqRDGHIVUICrgfuq6iNzNu0ANrXlTcANc9ovaVcDnQvsnTNVJEkasyF3A3018DZgZ5Ivt7bfBq4ArkuyGfgGcFHbdiOwAdgFPAlcOmDfkqSBFh0AVfWPQA6yef0B+hfwzsXuT5JWsnVbP7fP+gNXvGlClfyQ7wSWpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTQ94IJmkeZ20/6xltOzftnEAl0jN5BCBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKewFJUrP/vZuO9vs2GQA6KhyJ/3BbOtIZADo6feD4/db3TqYO6QhmAIyDL0aSjkCeBJakThkAktQpA0CSOmUASFKnPAmsw9LbddIrihcb6DAZAMvgGdekHzehQiTpEAwArQgeeUhLzwCQpEnYf8rutBePvQQDYKGcXx2vI+CX42mHOvrwFhRayQyAFcjpEE3akOAzNI8cBsBBeCJ36RlcCzCmI01fhAUTCIAk5wFXAccAn6yqK8Zdg/pj+EjPNNYASHIM8DHg54DdwBeT7Kiqe8dZh8bkCJrHl/RM4z4CeCWwq6ruB0jyV8BGwADonFNuh8+v2YF5tLdw4w6A1cBDc9Z3A+eMuYYj3nLOz/rLsQBDjlw86tEKkqoa386SC4HzquqX2/rbgHOq6l1z+mwBtrTVlwNfXcSuTga+NbDclabHMYPj7kmPY4bFjfslVTU1X6dxHwHsAdbOWV/T2n6gqrYB24bsJMlMVU0PeY6Vpscxg+OedB3j1OOYYXnHPe67gX4ROD3JaUmOBS4Gdoy5BkkSYz4CqKqnkrwL+Dyjy0A/VVX3jLMGSdLI2N8HUFU3Ajcu824GTSGtUD2OGRx3T3ocMyzjuMd6EliSdOTwP4JJUqdWbAAkOS/JV5PsSrL1ANufk+Tatv2OJOvGX+XSW8C4L0tyb5K7k9yc5CWTqHOpzTfuOf1+IUklWfFXiyxkzEkuat/ve5L85bhrXA4L+Bl/cZJbk9zVfs43TKLOpZTkU0keTfKVg2xPko+2r8ndSc5ekh1X1Yr7YHQC+d+BHweOBf4FOGO/Pr8KfKItXwxcO+m6xzTunwWe25bf0cu4W78XALcBtwPTk657DN/r04G7gBPb+o9Ouu4xjXsb8I62fAbwwKTrXoJxvwY4G/jKQbZvAP4eCHAucMdS7HelHgH84JYSVfVd4OlbSsy1Edjelq8H1ifJGGtcDvOOu6puraon2+rtjN5rsdIt5PsN8CHgw8B3xlncMlnImH8F+FhVPQ5QVY+OucblsJBxF/DCtnw88B9jrG9ZVNVtwGOH6LIRuKZGbgdOSHLq0P2u1AA40C0lVh+sT1U9BewFThpLdctnIeOeazOjvxpWunnH3Q6J11bVvvfRWLkW8r1+GfCyJP+U5PZ2p92VbiHj/gDw1iS7GV1R+O7xlDZRh/u7vyD+P4CjVJK3AtPAz0y6luWW5FnAR4C3T7iUcVvFaBrotYyO9G5LclZVPTHRqpbfLwJ/XlV/lORVwF8kObOqvj/pwlaalXoEMO8tJeb2SbKK0aHit8dS3fJZyLhJ8nrgd4Dzq+p/x1Tbcppv3C8AzgS+kOQBRnOkO1b4ieCFfK93Azuq6ntV9XXg3xgFwkq2kHFvBq4DqKp/Bo5jdL+co9mCfvcP10oNgIXcUmIHsKktXwjcUu1sygo277iTvAL4E0Yv/kfDnDDMM+6q2ltVJ1fVuqpax+jcx/lVNTOZcpfEQn7G/5bRX/8kOZnRlND94yxyGSxk3A8C6wGS/CSjAJgda5XjtwO4pF0NdC6wt6oeHvqkK3IKqA5yS4kkHwRmqmoHcDWjQ8NdjE6uXDy5ipfGAsf9B8Dzgb9u57wfrKrzJ1b0EljguI8qCxzz54E3JLkX+D/gN6pqRR/lLnDc7wP+NMl7GZ0QfvtK/+MuyWcYhfnJ7dzG5cCzAarqE4zOdWwAdgFPApcuyX5X+NdNkrRIK3UKSJI0kAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKn/h8RtGnNi//deAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the training marginals\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.616031</td>\n",
       "      <td>0.745200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515870</td>\n",
       "      <td>0.739333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.841968</td>\n",
       "      <td>0.793933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.866711</td>\n",
       "      <td>0.803267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Coverage\n",
       "0  0.616031  0.745200\n",
       "1  0.515870  0.739333\n",
       "2  0.841968  0.793933\n",
       "3  0.866711  0.803267"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learned accuracy parameters, and other statistics about the LFs learned by the generative model\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate on Labeling Functions\n",
    "Improve the LF set.  First, apply the LFs to the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.722222222222\n"
     ]
    }
   ],
   "source": [
    "# Get the score of the generative model\n",
    "correct, incorrect = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the training labels\n",
    "\n",
    "Save the `training_marginals` (**probabilistic training labels**) for later use to train an end extraction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1307 marginals\n",
      "CPU times: user 1.52 s, sys: 8 ms, total: 1.53 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an End Extraction Model\n",
    "Use the noisy training labels to train the end extraction model (Bi-LSTM, a state-of-the-art deep neural network). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99316579  0.00467239  0.00216182]\n",
      " [ 0.76777548  0.03885356  0.19337096]\n",
      " [ 0.99316579  0.00467239  0.00216182]\n",
      " ..., \n",
      " [ 0.00100509  0.00100509  0.99798982]\n",
      " [ 0.97854889  0.01466562  0.00678549]\n",
      " [ 0.98632122  0.00683939  0.00683939]]\n"
     ]
    }
   ],
   "source": [
    "# Reload the probabilistic training labels\n",
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the candidates\n",
    "train_cands = session.query(Exercise).filter(Exercise.split == 0).order_by(Exercise.id).all()\n",
    "dev_cands   = session.query(Exercise).filter(Exercise.split == 1).order_by(Exercise.id).all()\n",
    "test_cands  = session.query(Exercise).filter(Exercise.split == 2).order_by(Exercise.id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gold labels for evaluation\n",
    "#from snorkel.annotations import load_gold_labels\n",
    "#L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "#L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of train set\n",
    "train_candidates = [train_cands[i].content for i in range(len(train_cands))]\n",
    "Y_train = [t['label'] for c in train_candidates for (i, t) in tweets.iterrows() if c == t['content']] \n",
    "Y_train = np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of dev set\n",
    "dev_candidates = [dev_cands[i].content for i in range(len(dev_cands))]\n",
    "Y_dev = [t['label'] for c in dev_candidates for (i, t) in tweets.iterrows() if c == t['content']] \n",
    "Y_dev = np.asarray(Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of test set\n",
    "test_candidates = [test_cands[i].content for i in range(len(test_cands))]\n",
    "Y_test = [t['label'] for c in test_candidates for (i, t) in tweets.iterrows() if c == t['content']] \n",
    "Y_test = np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRNN] Training model\n",
      "[reRNN] n_train=1307  #epochs=10  batch size=256\n",
      "[reRNN] Epoch 0 (0.53s)\tAverage loss=0.992643\tDev Acc.=52.76\n",
      "[reRNN] Epoch 1 (0.95s)\tAverage loss=0.781714\tDev Acc.=54.60\n",
      "[reRNN] Epoch 2 (1.27s)\tAverage loss=0.566189\tDev Acc.=56.44\n",
      "[reRNN] Epoch 3 (1.58s)\tAverage loss=0.456253\tDev Acc.=57.06\n",
      "[reRNN] Epoch 4 (1.89s)\tAverage loss=0.422172\tDev Acc.=56.44\n",
      "[reRNN] Epoch 5 (2.20s)\tAverage loss=0.407709\tDev Acc.=56.44\n",
      "[reRNN] Epoch 6 (2.50s)\tAverage loss=0.372940\tDev Acc.=59.51\n",
      "[reRNN] Epoch 7 (2.80s)\tAverage loss=0.352447\tDev Acc.=55.83\n",
      "[reRNN] Epoch 8 (3.11s)\tAverage loss=0.356618\tDev Acc.=60.74\n",
      "[reRNN] Model saved as <reRNN>\n",
      "[reRNN] Epoch 9 (3.56s)\tAverage loss=0.351773\tDev Acc.=55.21\n",
      "[reRNN] Training done (3.57s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/reRNN/reRNN-8\n",
      "[reRNN] Loaded model <reRNN>\n"
     ]
    }
   ],
   "source": [
    "# Setup the discriminative model\n",
    "from snorkel.learning.disc_models.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        50,\n",
    "    'n_epochs':   10,\n",
    "    'dropout':    0.25,\n",
    "    'print_freq': 1\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=Y_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "train = 0.798, dev = 0.607, and test= 0.552\n"
     ]
    }
   ],
   "source": [
    "# Stats from the discriminative model\n",
    "train_cands_ac = lstm.score(train_cands, Y_train)\n",
    "dev_cands_ac = lstm.score(dev_cands, Y_dev)\n",
    "test_cands_ac = lstm.score(test_cands, Y_test)\n",
    "\n",
    "print(\"Accuracy Score:\\ntrain = {0:.3f}, dev = {1:.3f}, and test= {2:.3f}\".format(train_cands_ac, dev_cands_ac, test_cands_ac))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
