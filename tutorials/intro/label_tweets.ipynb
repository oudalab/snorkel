{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Snorkel Session and Load Data\n",
    "Creates a snorkel session on SQLite database and loads tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Exercise = candidate_subclass('Exercise', ['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "docs = []\n",
    "distinct_docs = []\n",
    "json_file = 'data/tweets.json'\n",
    "\n",
    "tweets = pd.read_json(json_file)\n",
    "for t in tweets['tweet']:\n",
    "    tweet = ast.literal_eval(t)\n",
    "    #docs.append(tweet['text'])\n",
    "    docs.append(' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet['text']).split()))    \n",
    "\n",
    "train_set = set()\n",
    "dev_set = set()\n",
    "test_set = set()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    if doc not in distinct_docs:\n",
    "        distinct_docs.append(doc)\n",
    "        if i % 10 == 8:\n",
    "            dev_set.add(doc)\n",
    "        elif i % 10 == 9:\n",
    "            test_set.add(doc)\n",
    "        else:\n",
    "            train_set.add(doc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "cand_extractor = CandidateExtractor(Exercise, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 7756)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 965)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 964)\n",
      "CPU times: user 2.61 s, sys: 244 ms, total: 2.85 s\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, docs in enumerate([train_set, dev_set, test_set]):    \n",
    "    cand_extractor.apply(docs, split=i)\n",
    "    print(\"Number of candidates:\", session.query(Exercise).filter(Exercise.split == i).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 965\n",
      "AnnotatorLabels created: 964\n",
      "CPU times: user 24.4 s, sys: 100 ms, total: 24.5 s\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "# Load Gold Labels\n",
    "from util import load_external_labels\n",
    "%time missed = load_external_labels(session, Exercise, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((965, 1), (964, 1))\n"
     ]
    }
   ],
   "source": [
    "# Load existing dev and test sets\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "print(L_gold_dev.shape, L_gold_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Functions (LFs)\n",
    "LF is a python function that accepts a tweet and returns 1 if it marks it as true, -1 if false, or 0 to abstain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks for a kb phrase in the tweet\n",
    "#kb = 'data/kb.txt'\n",
    "            \n",
    "#def LF_distant_supervision(c):   \n",
    "    #with open(kb) as f:\n",
    "        #for phrase in f:\n",
    "            #return 1 if c.find(phrase.strip()) >= 0 else -1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use weak classifier\n",
    "#import classifier\n",
    "\n",
    "#def LF_weak_classifier(c):\n",
    "    #return classify(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some random LF\n",
    "import random\n",
    "\n",
    "def LF_random_lf(c):\n",
    "    return random.choice([-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another random LF\n",
    "def LF_another_random_lf(c):\n",
    "    return random.choice([-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n"
     ]
    }
   ],
   "source": [
    "print(LF_random_lf('a'), LF_another_random_lf('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group LFs in a list for later use\n",
    "#LFs = [LF_distant_supervision, LF_weak_classifier, LF_random_lf, LF_another_random_lf]\n",
    "LFs = [LF_random_lf, LF_another_random_lf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number labeled:', 321)\n"
     ]
    }
   ],
   "source": [
    "# Check size of dev set labeled as exercise tweets using LF_random_lf\n",
    "labeled = []\n",
    "for c in session.query(Exercise).filter(Exercise.split == 1).all():\n",
    "    if LF_random_lf(c) == 1:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/redae/anaconda/envs/py2Env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.497\n",
      "Neg. class accuracy: 0.518\n",
      "Precision            0.265\n",
      "Recall               0.497\n",
      "F1                   0.346\n",
      "----------------------------------------\n",
      "TP: 79 | FP: 219 | TN: 235 | FN: 80\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of LF_random_lf on dev set\n",
    "from snorkel.lf_helpers import test_LF\n",
    "tp, fp, tn, fn = test_LF(session, LF_random_lf, split=1, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LFs\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 6.63 s, sys: 48 ms, total: 6.68 s\n",
      "Wall time: 6.81 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<7756x2 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 10311 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run labeler\n",
    "import numpy as np\n",
    "np.random.seed(1701)\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 4 ms, total: 124 ms\n",
      "Wall time: 124 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<7756x2 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 10311 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Load the labels as a sparse matrix\n",
    "%time L_train = labeler.load_matrix(session, split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_random_lf</th>\n",
       "      <td>0</td>\n",
       "      <td>0.666194</td>\n",
       "      <td>0.445591</td>\n",
       "      <td>0.222151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_another_random_lf</th>\n",
       "      <td>1</td>\n",
       "      <td>0.663228</td>\n",
       "      <td>0.445591</td>\n",
       "      <td>0.222151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      j  Coverage  Overlaps  Conflicts\n",
       "LF_random_lf          0  0.666194  0.445591   0.222151\n",
       "LF_another_random_lf  1  0.663228  0.445591   0.222151"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  View statistics about the resulting label matrix\n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generative Model\n",
    "\n",
    "Train a model of the LFs to estimate their accuracies and then combine the outputs of the LFs into a noise-aware training labels set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55207343,  0.55443033])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply gen model to the training candidates to get the noise-aware training label set (training marginals)\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the training marginals\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.739087</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>0.518839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.749207</td>\n",
       "      <td>0.6938</td>\n",
       "      <td>0.746427</td>\n",
       "      <td>0.526093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Coverage  Precision    Recall\n",
       "0  0.739087    0.7033   0.741007  0.518839\n",
       "1  0.749207    0.6938   0.746427  0.526093"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learned accuracy parameters, and other statistics about the LFs learned by the generative model\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate on Labeling Functions\n",
    "Improve the LF set.  First, we apply the LFs to our development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.447\n",
      "Neg. class accuracy: 0.586\n",
      "Precision            0.279\n",
      "Recall               0.447\n",
      "F1                   0.344\n",
      "----------------------------------------\n",
      "TP: 114 | FP: 294 | TN: 416 | FN: 141\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the score of the generative model\n",
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_random_lf</th>\n",
       "      <td>0</td>\n",
       "      <td>0.654922</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>0.201036</td>\n",
       "      <td>68</td>\n",
       "      <td>224</td>\n",
       "      <td>96</td>\n",
       "      <td>244</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.749426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_another_random_lf</th>\n",
       "      <td>1</td>\n",
       "      <td>0.652850</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>0.201036</td>\n",
       "      <td>94</td>\n",
       "      <td>209</td>\n",
       "      <td>70</td>\n",
       "      <td>257</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.748274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      j  Coverage  Overlaps  Conflicts  TP   FP  FN   TN  \\\n",
       "LF_random_lf          0  0.654922  0.435233   0.201036  68  224  96  244   \n",
       "LF_another_random_lf  1  0.652850  0.435233   0.201036  94  209  70  257   \n",
       "\n",
       "                      Empirical Acc.  Learned Acc.  \n",
       "LF_random_lf                0.493671      0.749426  \n",
       "LF_another_random_lf        0.557143      0.748274  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore some of the additional functionalities of the lf_stats method for the dev set\n",
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the training labels\n",
    "\n",
    "Save the `training_marginals` (**probabilistic training labels**) for later use to train an end extraction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 7756 marginals\n",
      "CPU times: user 3.96 s, sys: 40 ms, total: 4 s\n",
      "Wall time: 4.12 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
