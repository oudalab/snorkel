{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Snorkel Session and Load Data\n",
    "Creates a snorkel session on SQLite database and loads tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Exercise = candidate_subclass('Exercise', ['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "docs = []\n",
    "tweets_file_path = 'data/unlabeled_tweets.tsv'\n",
    "\n",
    "tweets = pd.read_csv(tweets_file_path, sep = '\\t')\n",
    "for idx, row in tweets.iterrows():\n",
    "    docs.append(row['content'])\n",
    "    \n",
    "train_set = set()\n",
    "dev_set = set()\n",
    "test_set = set()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    if i % 10 == 8:\n",
    "        dev_set.add(doc)\n",
    "    elif i % 10 == 9:\n",
    "        test_set.add(doc)\n",
    "    else:\n",
    "        train_set.add(doc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "cand_extractor = CandidateExtractor(Exercise, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, docs in enumerate([train_set, dev_set, test_set]):    \n",
    "    cand_extractor.apply(docs, split=i)\n",
    "    print(\"Number of candidates:\", session.query(Exercise).filter(Exercise.split == i).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Gold Labels\n",
    "from util import load_external_labels\n",
    "%time missed = load_external_labels(session, Exercise, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing dev and test sets\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "print(L_gold_dev.shape, L_gold_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Functions (LFs)\n",
    "LF is a python function that accepts a tweet and returns 1 if it marks it relevant, 2 if irrelevant, 3 if junk, or 0 to abstain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks for a kb phrase in the tweet\n",
    "kb = 'data/kb.txt'\n",
    "def is_exercise(c):\n",
    "    with open(kb) as f:\n",
    "        for phrase in f:\n",
    "            if c.content.find(phrase.strip()) >= 0:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Look for person names\n",
    "def has_person(c):\n",
    "    ents = [e.label_ for e in nlp(c.content).ents]\n",
    "    for l in ents:\n",
    "        if l == 'PERSON':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person = []\n",
    "other_person = []\n",
    "pronouns_path = 'data/pronouns.tsv'\n",
    "\n",
    "pronouns = pd.read_csv(pronouns_path, sep = '\\t')\n",
    "\n",
    "for idx, row in pronouns.iterrows():\n",
    "    if row['category'] == 1:\n",
    "        first_person.append(row['pronoun'])\n",
    "    else:\n",
    "        other_person.append(row['pronoun'])        \n",
    "\n",
    "def LF_1(c):\n",
    "    if is_exercise(c):\n",
    "        for pronoun in first_person:\n",
    "            if pronoun in c.content.split():\n",
    "                #print('me = {0} => {1}'.format(me, c.content))\n",
    "                return 1\n",
    "        return 0\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_2(c):\n",
    "    if is_exercise(c):\n",
    "        if has_person(c):\n",
    "            return 2\n",
    "        else:\n",
    "            for pronoun in other_person:\n",
    "                if pronoun in c.content.split():   \n",
    "                    #print('other = {0} => {1}'.format(o, c.content))\n",
    "                    return 2\n",
    "            return 0\n",
    "    return 3               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_3(c):    \n",
    "    for idx, tweet in tweets.iterrows():\n",
    "        if c.content == tweet['content']:\n",
    "            #print('content = {0}, label = {1}'.format(c.content, tweet['label']))\n",
    "            return tweet['label']\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use weak classifier\n",
    "from snorkel.weak_classifier import train_classifier, classify\n",
    "\n",
    "# First train the classifier\n",
    "vec, clf = train_classifier()\n",
    "\n",
    "def LF_weak_classifier(c):\n",
    "    label = classify(vec, clf, [c.content])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group LFs in a list for later use\n",
    "LFs = [LF_1, LF_2, LF_3, LF_weak_classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check size of dev set labeled as exercise tweets using LF_weak_classifier\n",
    "labeled = []\n",
    "for c in session.query(Exercise).filter(Exercise.split == 1):\n",
    "    if LF_weak_classifier(c) == 1:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LFs\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run labeler\n",
    "import numpy as np\n",
    "np.random.seed(1701)\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels as a sparse matrix\n",
    "%time L_train = labeler.load_matrix(session, split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View statistics about the resulting label matrix\n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generative Model\n",
    "\n",
    "Train a model of the LFs to estimate their accuracies and then combine the outputs of the LFs into a noise-aware training labels set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model.weights.lf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply gen model to the training candidates to get the noise-aware training label set (training marginals)\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the training marginals\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned accuracy parameters, and other statistics about the LFs learned by the generative model\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate on Labeling Functions\n",
    "Improve the LF set.  First, apply the LFs to the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the score of the generative model\n",
    "correct, incorrect = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the training labels\n",
    "\n",
    "Save the `training_marginals` (**probabilistic training labels**) for later use to train an end extraction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an End Extraction Model\n",
    "Use the noisy training labels to train the end extraction model (Bi-LSTM, a state-of-the-art deep neural network). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the probabilistic training labels\n",
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the candidates\n",
    "train_cands = session.query(Exercise).filter(Exercise.split == 0).order_by(Exercise.id).all()\n",
    "dev_cands   = session.query(Exercise).filter(Exercise.split == 1).order_by(Exercise.id).all()\n",
    "test_cands  = session.query(Exercise).filter(Exercise.split == 2).order_by(Exercise.id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gold labels for evaluation\n",
    "#from snorkel.annotations import load_gold_labels\n",
    "#L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "#L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of train set\n",
    "train_candidates = [train_cands[i].content for i in range(len(train_cands))]\n",
    "Y_train = [t['label'] for c in train_candidates for (i, t) in tweets.iterrows() if c == t['content']] \n",
    "Y_train = np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of dev set\n",
    "dev_candidates = [dev_cands[i].content for i in range(len(dev_cands))]\n",
    "Y_dev = [t['label'] for c in dev_candidates for (i, t) in tweets.iterrows() if c == t['content']] \n",
    "Y_dev = np.asarray(Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of test set\n",
    "test_candidates = [test_cands[i].content for i in range(len(test_cands))]\n",
    "Y_test = [t['label'] for c in test_candidates for (i, t) in tweets.iterrows() if c == t['content']] \n",
    "Y_test = np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the discriminative model\n",
    "from snorkel.learning.disc_models.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        50,\n",
    "    'n_epochs':   10,\n",
    "    'dropout':    0.25,\n",
    "    'print_freq': 1\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=Y_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats from the discriminative model\n",
    "train_cands_ac = lstm.score(train_cands, Y_train)\n",
    "dev_cands_ac = lstm.score(dev_cands, Y_dev)\n",
    "test_cands_ac = lstm.score(test_cands, Y_test)\n",
    "\n",
    "print(\"Accuracy Score:\\ntrain = {0:.3f}, dev = {1:.3f}, and test= {2:.3f}\".format(train_cands_ac, dev_cands_ac, test_cands_ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cleaned jupyter notebook for version control\n",
    "import os\n",
    "\n",
    "notebook_path = os.path.join(os.getcwd(),'label_tweets.ipynb')\n",
    "cleaned_path = os.path.join(os.getcwd(),'tweets_labeler.ipynb')\n",
    "\n",
    "!cat {notebook_path} | nbstripout > {cleaned_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
